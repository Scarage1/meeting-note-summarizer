Title: Build “Meeting Note Summarizer” – pro-grade Next.js app with local Whisper ASR, clean UI, and export features

You are the senior engineer implementing this project end‑to‑end. Operate with precision and minimal diffs. Keep to the plan rigidly. At each step: propose tiny changes, apply them, run commands, and confirm outcomes.

North star

Vision: A privacy‑first meeting assistant that transcribes audio locally, summarizes into actionable notes, and exports clean artifacts users can share immediately.

Core constraints:

Offline speech-to-text using a local service (Express + @xenova/transformers Whisper) on port 9000.

Next.js App Router UI on port 3000.

No cloud keys required to run; optional adapters can be added later behind flags.

Monorepo layout

my-app/ → Next.js app

local-asr/ → Express service using @xenova/transformers Whisper

Non-negotiable API contracts

POST /api/transcribe → returns:
{ text: string, segments: Array<{start:number,end:number,text:string}>, language: string, model: string }

POST /api/summarize → accepts { transcript } and returns:
{ markdown: string, outline?: string[], actions?: Array<{owner?:string,task:string,due?:string}> }

Deliverables

Polished UI: elegant upload/record page, live progress states, pretty Markdown rendering, light/dark mode, mobile responsiveness, keyboard shortcuts.

Summarization: deterministic formatter first; optional local LLM (Ollama) adapter second.

Exporters: Markdown download, PDF print, and .ics calendar file for action items.

DX: scripts, README, .gitignore, lint/format, basic tests for API routes.

Workflow overview

Terminal A: local-asr (9000)

Terminal B: my-app (3000)

Browser: /upload → upload/record → transcript JSON → Summarize → Markdown notes → Export (MD/PDF/ICS)

Step 0 — Repo sanity and guardrails

Print a focused tree of my-app and local-asr.

If files are missing, create them exactly as defined below.

Add .gitignore at root and project level to exclude node_modules, .next, dist, uploads, .env.local.

Step 1 — local ASR service (rock-solid)

local-asr/package.json (CommonJS):

"type": "commonjs"

scripts:

"dev": "ts-node src/server.ts"

"build": "tsc"

"start": "node dist/server.js"

deps: express, multer, @xenova/transformers

devDeps: typescript, ts-node, @types/express, @types/multer

local-asr/tsconfig.json:
{
"compilerOptions": {
"target": "ES2020",
"module": "CommonJS",
"esModuleInterop": true,
"moduleResolution": "Node",
"skipLibCheck": true,
"outDir": "dist"
},
"include": ["src"]
}

local-asr/src/server.ts:

Initialize Whisper once:
pipeline("automatic-speech-recognition","Xenova/whisper-small")

POST /transcribe:

multer upload to uploads/

options: chunk_length_s: 30, stride_length_s: 5, return_timestamps: "word", language: "en"

return normalized JSON per contract

GET / → “ASR OK”

Commands to run and expected output:

cd local-asr && npm i && npm run dev

Expect: “Local ASR on http://localhost:9000”

Step 2 — Next.js app scaffolding

my-app/app/upload/page.tsx renders the UploadForm.

my-app/app/upload-form.tsx (client):

File input accept="audio/,video/"

POST to /api/transcribe via FormData; show JSON

Summarize button POSTs { transcript } to /api/summarize; renders formatted Markdown

Nice UX:

Tailwind classes

Disabled states and toasts for errors

Dropzone and paste support

Loading skeletons

my-app/app/api/transcribe/route.ts:

export const runtime = "nodejs"

Reads req.formData(), forwards file to http://localhost:9000/transcribe, returns JSON

Strong error messages with upstream details

my-app/app/api/summarize/route.ts (deterministic v1):

export const runtime = "nodejs"

formatMarkdownSummary(transcript) building:

Meeting overview (auto language + duration if present)
Discussion highlights (first 8 segments with timestamps)
Decisions (bullet list; may be empty)
Action items (owner/task/due placeholders)
Risks
Next steps
returns { markdown, outline, actions }

Step 3 — Professional UI polish

Global:

Tailwind configured (already in Next starter); add a refined theme with CSS variables for neutral gray, indigo accents.

Add a responsive container and header with brand text “Meeting Notes”.

Add dark mode toggle stored in localStorage.

Upload page enhancements:

Drag‑and‑drop zone with dashed border and hover highlight.

Audio recorder (MediaRecorder) to record mic input to WebM/Opus and submit.

Progress indicator while uploading/transcribing (indeterminate spinner).

Tabs: Transcript | Summary.

Pretty Markdown renderer (rehype/remark) with prose typography.

Sticky action bar: “Summarize”, “Export MD”, “Export PDF”, “Export .ics”.

Keyboard shortcuts:

U → focus file input

S → summarize

Cmd/Ctrl+D → download Markdown

Accessibility:

Labels for inputs, aria-live regions for status, and focus rings.

Mobile:

Single column layout, large buttons, no overflow on code blocks.

Step 4 — Export features

Markdown download:

Create a small utility to save a Blob as filename.md.

PDF:

Use window.print() with a print stylesheet that formats the summary page cleanly; avoid heavy deps.

ICS:

Parse action items and generate a simple .ics with VEVENT entries (start date = today + 3 days default).

Filename: meeting-actions.ics

Step 5 — Optional LLM adapter (behind a flag)

my-app/app/api/summarize/route.ts:

Add query ?engine=ollama or header X-Engine: ollama

If engine=ollama, POST to http://localhost:11434/api/generate with a prompt that instructs a concise Markdown meeting summary and structured JSON for actions, then map back to the same response shape.

Keep deterministic path as the default. If Ollama not running, return a clear 503 explaining how to start it.

Provide prompt tuned for Markdown sections, decisions, actions with owners when detectable, and dates.

Step 6 — DX, quality, and docs

Add scripts:

lint, format, typecheck

Basic tests (lightweight):

A unit test for formatMarkdownSummary to ensure deterministic output given a sample transcript.

README at repo root:

One-paragraph pitch, features, screenshots, and “Run locally” steps (two terminals).

API contracts table and example payloads.

Notes on model sizes: tiny/base/small trade-offs; how to switch.

.gitignore updates:

my-app: .next, node_modules, .env.local

local-asr: node_modules, dist, uploads

Step 7 — Final QA script

Run sequence:

Terminal A: cd local-asr && npm run dev (expect “ASR OK”)

Terminal B: cd my-app && npm i && npm run dev (expect Next ready)

Open /upload

Drag an audio file or record 10s sample

Confirm JSON transcript; click Summarize

Inspect Markdown, use Export buttons

Optional: start Ollama and test engine=ollama path

Capture a set of screenshots for README.

Rules of engagement

Keep all changes minimal and focused; do not introduce new libraries unless listed above or strictly necessary.

Maintain the two API contracts unchanged.

If an error appears, stop and provide:

The error text

Why it happened in one sentence

The smallest code diff to fix it

After each step, run and verify; do not proceed if the previous step isn’t green.

Now execute Step 0. Print the tree of relevant files. If any are missing or misplaced, create them with minimal code that satisfies the contracts, then run Step 1.

in more detail everything for scratch so i can add to readme file

in more detail everything for scratch so i can add to readme file
Below is a detailed, from‑scratch README template tailored to this project. It includes setup, architecture, contracts, code snippets, run commands, and troubleshooting so it can be followed end‑to‑end.

Title
Meeting Note Summarizer — Local Whisper ASR + Next.js

Overview
A privacy‑first meeting assistant that runs speech‑to‑text locally and produces clean, shareable meeting notes. Audio never leaves the machine. Built with a Next.js App Router frontend and a local Express microservice powered by @xenova/transformers Whisper.

Key features

Local transcription: Whisper models run fully on device; no API keys required.

Clean UI: upload or record audio, view transcript JSON, and generate Markdown notes.

Exports: download Markdown, print‑to‑PDF, and generate .ics calendar entries for action items.

Extensible: optional local LLM adapter (Ollama) for richer summaries, behind a simple flag.

Monorepo structure

my-app/ — Next.js UI + API (port 3000).

local-asr/ — Express + Whisper ASR (port 9000).

System requirements

Node.js 18.18+ or 20+ (recommended).

npm 9+.

OS: Windows, macOS, or Linux.

For faster transcription: multi‑core CPU; optional GPU/WebGPU setups can be explored later.

Quick start

Terminal A

cd local-asr

npm install

npm run dev

Expect: “Local ASR on http://localhost:9000” and GET / → “ASR OK” if health route enabled.

Terminal B

cd my-app

npm install

npm run dev

Open http://localhost:3000/upload, select audio, then click Summarize.

API contracts

Transcription

Method: POST /api/transcribe (Next.js) → proxies to local ASR at http://localhost:9000/transcribe.

Request: multipart/form-data with file field "file".

Response:
{
"text": "full transcript",
"segments": [
{ "start": 0.0, "end": 3.2, "text": "Hello everyone..." }
],
"language": "en",
"model": "Xenova/whisper-small"
}

Summarization

Method: POST /api/summarize

Request: { "transcript": { ...same shape as above } }

Response:
{
"markdown": "# Meeting overview\n...",
"outline": ["Agenda", "Decisions", "..."],
"actions": [{ "owner": "TBD", "task": "Action item", "due": "TBD" }]
}

local-asr implementation

package.json (CommonJS)
{
"name": "local-asr",
"version": "1.0.0",
"type": "commonjs",
"scripts": {
"dev": "ts-node src/server.ts",
"build": "tsc",
"start": "node dist/server.js"
},
"dependencies": {
"@xenova/transformers": "^2.17.2",
"express": "^5.1.0",
"multer": "^2.0.2"
},
"devDependencies": {
"@types/express": "^5.0.3",
"@types/multer": "^2.0.0",
"ts-node": "^10.9.2",
"typescript": "^5.9.2"
}
}

tsconfig.json
{
"compilerOptions": {
"target": "ES2020",
"module": "CommonJS",
"esModuleInterop": true,
"moduleResolution": "Node",
"skipLibCheck": true,
"outDir": "dist"
},
"include": ["src"]
}

src/server.ts
import express from "express";
import multer from "multer";
import fs from "node:fs";
import path from "node:path";
import { env, pipeline } from "@xenova/transformers";

env.allowLocalModels = true;
env.backends.onnx.wasm.numThreads = 1;

const upload = multer({ dest: path.join(process.cwd(), "uploads") });
const app = express();

let transcriber: any;
async function getTranscriber() {
if (!transcriber) {
transcriber = await pipeline("automatic-speech-recognition", "Xenova/whisper-small");
}
return transcriber;
}

app.post("/transcribe", upload.single("file"), async (req, res) => {
try {
if (!req.file) return res.status(400).json({ error: "file missing" });
const filePath = req.file.path;

text
const asr = await getTranscriber();
const result = await asr(fs.createReadStream(filePath), {
  chunk_length_s: 30,
  stride_length_s: 5,
  return_timestamps: "word",
  language: "en",
});

fs.unlink(filePath, () => {});
const normalized = {
  text: result.text,
  segments: result.segments ?? [],
  language: result.language ?? "auto",
  model: "Xenova/whisper-small",
};

res.json(normalized);
} catch (e: any) {
console.error(e);
res.status(500).json({ error: e?.message || "asr failed" });
}
});

app.get("/", (_req, res) => res.send("ASR OK"));

const PORT = process.env.PORT || 9000;
app.listen(PORT, () => console.log(Local ASR on http://localhost:${PORT}));

my-app implementation

app/upload/page.tsx
import UploadForm from "../upload-form";

export default function UploadPage() {
return (
<main className="mx-auto max-w-2xl p-6">
<h1 className="text-2xl font-semibold mb-4">Upload & Transcribe</h1>
<UploadForm />
</main>
);
}

app/upload-form.tsx
"use client";

import { useEffect, useRef, useState } from "react";

export default function UploadForm() {
const [transcript, setTranscript] = useState<any>(null);
const [loading, setLoading] = useState(false);
const [error, setError] = useState<string | null>(null);
const [summary, setSummary] = useState<string | null>(null);
const [summarizing, setSummarizing] = useState(false);

async function onSubmit(e: React.FormEvent<HTMLFormElement>) {
e.preventDefault();
setError(null); setTranscript(null); setSummary(null);
setLoading(true);
const form = e.currentTarget;
const fileInput = (form.elements.namedItem("file") as HTMLInputElement) || null;
const file = fileInput?.files?.;
if (!file) { setError("Please select an audio file."); setLoading(false); return; }

text
const fd = new FormData();
fd.append("file", file);
fd.append("response_format", "verbose_json");
fd.append("timestamp_granularities[]", "segment");

try {
  const res = await fetch("/api/transcribe", { method: "POST", body: fd });
  if (!res.ok) throw new Error(await res.text());
  const json = await res.json();
  setTranscript(json);
} catch (err: any) {
  setError(err?.message || "Upload failed");
} finally {
  setLoading(false);
}
}

async function onSummarize() {
if (!transcript) return;
setSummarizing(true); setError(null); setSummary(null);
try {
const res = await fetch("/api/summarize", {
method: "POST",
headers: { "Content-Type": "application/json" },
body: JSON.stringify({ transcript }),
});
if (!res.ok) throw new Error(await res.text());
const json = await res.json();
setSummary(json.markdown);
} catch (err: any) {
setError(err?.message || "Summarization failed");
} finally {
setSummarizing(false);
}
}

function download(filename: string, content: string, type = "text/plain") {
const blob = new Blob([content], { type });
const url = URL.createObjectURL(blob);
const a = document.createElement("a"); a.href = url; a.download = filename; a.click();
URL.revokeObjectURL(url);
}

function downloadICS() {
const dtStart = new Date(Date.now() + 3 * 24 * 3600 * 1000).toISOString().replace(/[-:]/g, "").split(".") + "Z";
const lines = [
"BEGIN:VCALENDAR", "VERSION:2.0", "PRODID:-//Meeting Note Summarizer//EN",
"BEGIN:VEVENT",
UID:${Date.now()}@local,
DTSTAMP:${dtStart},
DTSTART:${dtStart},
"SUMMARY:Meeting action items",
"DESCRIPTION:Follow up on meeting actions",
"END:VEVENT",
"END:VCALENDAR"
];
download("meeting-actions.ics", lines.join("\r\n"), "text/calendar");
}

return (
<div>
<form onSubmit={onSubmit} className="space-y-4">
<input type="file" name="file" accept="audio/*,video/*" />
<button type="submit" className="px-4 py-2 rounded bg-black text-white disabled:opacity-50" disabled={loading}>
{loading ? "Transcribing..." : "Upload & Transcribe"}
</button>
</form>

text
  {error && <p className="text-red-600 mt-4">{error}</p>}

  {transcript && (
    <>
      <pre className="mt-4 p-3 bg-gray-100 rounded text-sm overflow-x-auto">
        {JSON.stringify(transcript, null, 2)}
      </pre>
      <div className="mt-3 flex items-center gap-2">
        <button type="button" onClick={onSummarize} className="px-3 py-2 rounded bg-indigo-600 text-white disabled:opacity-50" disabled={summarizing}>
          {summarizing ? "Summarizing..." : "Summarize"}
        </button>
        {summary && (
          <>
            <button type="button" onClick={() => download("meeting-notes.md", summary)} className="px-3 py-2 rounded bg-slate-800 text-white">
              Export MD
            </button>
            <button type="button" onClick={() => window.print()} className="px-3 py-2 rounded bg-slate-700 text-white">
              Print PDF
            </button>
            <button type="button" onClick={downloadICS} className="px-3 py-2 rounded bg-slate-700 text-white">
              Export .ics
            </button>
          </>
        )}
      </div>
    </>
  )}

  {summary && (
    <div className="mt-4 p-4 border rounded prose prose-slate dark:prose-invert max-w-none">
      <h2 className="text-lg font-semibold mb-2">Summary</h2>
      <pre className="whitespace-pre-wrap">{summary}</pre>
    </div>
  )}
</div>
);
}

app/api/transcribe/route.ts
import { NextResponse } from "next/server";

export const runtime = "nodejs";

export async function POST(req: Request) {
try {
const formData = await req.formData();
const file = formData.get("file") as File | null;
if (!file) return NextResponse.json({ error: "Missing file" }, { status: 400 });

text
const proxyForm = new FormData();
proxyForm.append("file", file, (file as any).name || "audio.webm");

const asrRes = await fetch("http://localhost:9000/transcribe", { method: "POST", body: proxyForm });
if (!asrRes.ok) throw new Error(`ASR error: ${asrRes.status} ${await asrRes.text()}`);

const json = await asrRes.json();
return NextResponse.json(json, { status: 200 });
} catch (e: any) {
console.error(e);
return NextResponse.json({ error: e?.message || "Transcription failed" }, { status: 500 });
}
}

app/api/summarize/route.ts
import { NextResponse } from "next/server";

export const runtime = "nodejs";

function formatMarkdownSummary(transcript: any) {
const segs = Array.isArray(transcript?.segments) ? transcript.segments : [];
const hi = segs.slice(0, 8).map((s: any) => - (${typeof s.start === "number" ? s.start.toFixed(1) : "?"}s) ${s.text ?? ""}).join("\n");
return [
"# Meeting overview",
"- Summary: Auto-generated draft from transcript segments.",
"",
"## Discussion highlights",
hi || "- Highlights unavailable.",
"",
"## Decisions",
"- [TBD]",
"",
"## Action items",
"- [Owner TBD] Action item inferred from discussion.",
"",
"## Risks",
"- [TBD]",
"",
"## Next steps",
"- Define owners and deadlines for action items."
].join("\n");
}

export async function POST(req: Request) {
try {
const body = await req.json();
const transcript = body?.transcript;
if (!transcript) return NextResponse.json({ error: "Missing transcript" }, { status: 400 });
const markdown = formatMarkdownSummary(transcript);
return NextResponse.json({ markdown, outline: [], actions: [] }, { status: 200 });
} catch (e: any) {
console.error(e);
return NextResponse.json({ error: e?.message || "Summarization failed" }, { status: 500 });
}
}

Styling and UX tips

Use Tailwind Typography for nicer Markdown: @tailwindcss/typography; render the summary inside a prose container.

Add a header and footer with brand text, GitHub link, and theme toggle.

Keep UI components accessible with labels, aria-live for status, and keyboard shortcuts.

Troubleshooting

“Cannot GET /” on http://localhost:9000: expected; add GET / health route for “ASR OK”, and always POST /transcribe via the Next API.

ERR_UNKNOWN_FILE_EXTENSION .ts in local-asr: set "type":"commonjs" and run with ts-node; or compile with tsc and run dist/server.js.

Next.js fails to compile: check Node version ≥ 18.18, fix any TypeScript errors in route handlers, and ensure export const runtime = "nodejs".

CORS not required: Next server proxies to local ASR; both run on localhost; avoid direct browser calls to :9000.

Roadmap (optional)

LLM adapter (Ollama): add engine switch in /api/summarize; prompt to produce concise Markdown plus structured actions; keep output contract identical.

Speaker diarization: integrate pyannote or model-supported timestamps later; annotate segments by speaker.

Chaptering and topic tags: cluster segments and generate a table of contents.

File persistence: optional SQLite/Prisma to store transcripts and summaries locally.

License

Apache-2.0 (recommended for permissive use with patent grant).

Credits

Whisper via @xenova/transformers for local ASR.

Next.js App Router scaffold and Tailwind CSS.

